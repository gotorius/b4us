{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e028601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "import torch.nn.functional as F\n",
    "import functools\n",
    "from torch.optim import Adam\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, recall_score, precision_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2783e7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075aacae028d4deba7f602fe1ad96c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_362939/2211473014.py:159: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   0%|          | 0/4096 [00:00<?, ?it/s]/tmp/ipykernel_362939/2211473014.py:175: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=True):\n",
      "Epoch 1/50: 100%|██████████| 4096/4096 [22:10<00:00,  3.08it/s, loss=0.608]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training Loss: 0.6327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_362939/2211473014.py:193: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy after epoch 1: 78.04%\n",
      "Best model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████| 4096/4096 [22:05<00:00,  3.09it/s, loss=0.598]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training Loss: 0.4981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy after epoch 2: 83.07%\n",
      "Best model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50:  79%|███████▉  | 3243/4096 [17:31<04:34,  3.11it/s, loss=0.591]"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import timm\n",
    "from timm.scheduler.cosine_lr import CosineLRScheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchsampler import ImbalancedDatasetSampler\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, recall_score, precision_score, confusion_matrix\n",
    "\n",
    "# --- Mixup関数 ---\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, acc):\n",
    "        score = acc\n",
    "        if self.best_score is None or score > self.best_score:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "class PCamDataset(Dataset):\n",
    "    def __init__(self, h5_x_path, h5_y_path=None, transform=None):\n",
    "        self.x_path = h5_x_path\n",
    "        self.y_path = h5_y_path\n",
    "        self.transform = transform\n",
    "        self.has_labels = h5_y_path is not None\n",
    "\n",
    "        self.x_file = h5py.File(h5_x_path, 'r')\n",
    "        self.length = len(self.x_file['x'])\n",
    "\n",
    "        if self.has_labels:\n",
    "            self.y_file = h5py.File(h5_y_path, 'r')\n",
    "            self.labels = self.y_file['y'][:]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.x_file['x'][idx].astype(np.uint8)\n",
    "        image = transforms.ToPILImage()(image)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.has_labels:\n",
    "            label = self.labels[idx].item() \n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "    def __del__(self):\n",
    "        if hasattr(self, 'x_file'):\n",
    "            self.x_file.close()\n",
    "        if self.has_labels and hasattr(self, 'y_file'):\n",
    "            self.y_file.close()\n",
    "\n",
    "    def get_labels(self):\n",
    "        if self.has_labels:\n",
    "            return self.labels.reshape(-1)  # 1次元に変換\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "# RandAugment + (0.5,0.5,0.5)正規化\n",
    "mean = [0.5, 0.5, 0.5]\n",
    "std = [0.5, 0.5, 0.5]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((96, 96)),\n",
    "    transforms.RandAugment(num_ops=2, magnitude=14),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize(96),\n",
    "    transforms.CenterCrop(96),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "train_dataset = PCamDataset(\n",
    "    '/home/gotou/Medical/b4us/pcamdata/camelyonpatch_level_2_split_train_x.h5',\n",
    "    '/home/gotou/Medical/b4us/pcamdata/camelyonpatch_level_2_split_train_y.h5',\n",
    "    transform=train_transform\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, sampler=ImbalancedDatasetSampler(train_dataset), num_workers=4)\n",
    "\n",
    "val_dataset = PCamDataset(\n",
    "    '/home/gotou/Medical/b4us/pcamdata/valid_x_uncompressed.h5',\n",
    "    '/home/gotou/Medical/b4us/pcamdata/valid_y_uncompressed.h5',\n",
    "    transform=eval_transform\n",
    ")\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# --- モデル選択 ---\n",
    "model_name = 'resnet50'  # 例: 'resnet50', 'efficientnet_b1', 'vit_base_patch16_224' など\n",
    "num_classes = 2\n",
    "model = timm.create_model(model_name, pretrained=True, num_classes=num_classes)\n",
    "\n",
    "if torch.cuda.is_available() and torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "    model = nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "\n",
    "# --- Optimizer選択 ---\n",
    "optimizer_name = 'adam'  # 'adam' or 'sgd'\n",
    "lr = 1e-4\n",
    "if optimizer_name == 'adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "elif optimizer_name == 'sgd':\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "else:\n",
    "    raise ValueError('Unknown optimizer')\n",
    "\n",
    "# --- CosineLRScheduler (timm) ウォームアップ付き ---\n",
    "n_epochs = 50\n",
    "scheduler = CosineLRScheduler(optimizer, t_initial=n_epochs, lr_min=lr*0.05, warmup_t=int(0.05*n_epochs), warmup_lr_init=lr*0.05, warmup_prefix=True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
    "\n",
    "best_acc = 0\n",
    "train_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "early_stopping = EarlyStopping(patience=7, verbose=True)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{n_epochs}\")\n",
    "    for imgs, labels in loop:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        imgs_mix, targets_a, targets_b, lam = mixup_data(imgs, labels, alpha=0.4)\n",
    "        with torch.cuda.amp.autocast(enabled=True):\n",
    "            outputs = model(imgs_mix)\n",
    "            loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1} Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            with torch.cuda.amp.autocast(enabled=True):\n",
    "                outputs = model(imgs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    acc = 100 * correct / total\n",
    "    print(f\"Validation accuracy after epoch {epoch+1}: {acc:.2f}%\")\n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_accuracies.append(acc)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        torch.save(model.state_dict(), 'bestresnet50.pth')\n",
    "        print(\"Best model saved.\")\n",
    "    scheduler.step(epoch+1)\n",
    "    early_stopping(acc)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping!\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
